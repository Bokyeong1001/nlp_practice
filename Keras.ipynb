{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "verified-simpson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences :  [1, 2, 3, 4, 6, 7]\n",
      "word_index :  {'the': 1, 'earth': 2, 'is': 3, 'an': 4, 'awesome': 5, 'place': 6, 'live': 7}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "t  = Tokenizer()\n",
    "fit_text = \"The earth is an awesome place live\"\n",
    "t.fit_on_texts([fit_text])\n",
    "\n",
    "test_text = \"The earth is an great place live\"\n",
    "sequences = t.texts_to_sequences([test_text])[0]\n",
    "\n",
    "print(\"sequences : \",sequences) # great는 단어 집합(vocabulary)에 없으므로 출력되지 않는다.\n",
    "print(\"word_index : \",t.word_index) # 단어 집합(vocabulary) 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exciting-being",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [0, 7, 8]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "pad_sequences([[1, 2, 3], [3, 4, 5, 6], [7, 8]], maxlen=3, padding='pre')\n",
    "# 전처리가 끝나서 각 단어에 대한 정수 인코딩이 끝났다고 가정하고, 3개의 데이터를 입력으로 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sunset-chambers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) # 출력층\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "norwegian-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 코드는 뒤의 텍스트 분류 챕터의 스팸 메일 분류하기 실습 코드를 갖고온 것임.\n",
    "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "max_features = 10000\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32)) #RNN에 대한 설명은 뒤의 챕터에서 합니다.\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "# 위의 compile() 코드의 연장선상인 코드\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터의 20%를 검증 데이터로 사용.\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0, validation_split=0.2))\n",
    "\"\"\"\"\n",
    "verbose = 학습 중 출력되는 문구를 설정합니다.\n",
    "- 0 : 아무 것도 출력하지 않습니다.\n",
    "- 1 : 훈련의 진행도를 보여주는 진행 막대를 보여줍니다.\n",
    "- 2 : 미니 배치마다 손실 정보를 출력합니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 fit() 코드의 연장선상인 코드\n",
    "model.predict(X_input, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_name.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"model_name.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-madonna",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fully connected layer\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "inputs = Input(shape=(10,))\n",
    "hidden1 = Dense(64, activation='relu')(inputs)\n",
    "hidden2 = Dense(64, activation='relu')(hidden1)\n",
    "output = Dense(1, activation='sigmoid')(hidden2)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(3,))\n",
    "output = Dense(1, activation='linear')(inputs)\n",
    "linear_model = Model(inputs, output)\n",
    "\n",
    "linear_model.compile(optimizer='sgd', loss='mse')\n",
    "linear_model.fit(x=dat_test, y=y_cts_test, epochs=50, verbose=0)\n",
    "linear_model.fit(x=dat_test, y=y_cts_test, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(3,))\n",
    "output = Dense(1, activation='sigmoid')(inputs)\n",
    "logistic_model = Model(inputs, output)\n",
    "\n",
    "logistic_model.compile(optimizer='sgd', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "logistic_model.optimizer.lr = 0.001\n",
    "logistic_model.fit(x=dat_train, y=y_classifier_train, epochs = 5, validation_data = (dat_test, y_classifier_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "portuguese-gnome",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6bed36709967>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#multiple input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 최종 완성된 다중 입력, 다중 출력 모델의 예\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Model' is not defined"
     ]
    }
   ],
   "source": [
    "#multiple input\n",
    "# 최종 완성된 다중 입력, 다중 출력 모델의 예\n",
    "model=Model(inputs=[a1, a2], outputs=[b1, b2, b3])\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 두 개의 입력층을 정의\n",
    "inputA = Input(shape=(64,))\n",
    "inputB = Input(shape=(128,))\n",
    "\n",
    "# 첫번째 입력층으로부터 분기되어 진행되는 인공 신경망을 정의\n",
    "x = Dense(16, activation=\"relu\")(inputA)\n",
    "x = Dense(8, activation=\"relu\")(x)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "\n",
    "# 두번째 입력층으로부터 분기되어 진행되는 인공 신경망을 정의\n",
    "y = Dense(64, activation=\"relu\")(inputB)\n",
    "y = Dense(32, activation=\"relu\")(y)\n",
    "y = Dense(8, activation=\"relu\")(y)\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "\n",
    "# 두개의 인공 신경망의 출력을 연결(concatenate)\n",
    "result = concatenate([x.output, y.output])\n",
    "\n",
    "# 연결된 값을 입력으로 받는 밀집층을 추가(Dense layer)\n",
    "z = Dense(2, activation=\"relu\")(result)\n",
    "# 선형 회귀를 위해 activation=linear를 설정\n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "# 결과적으로 이 모델은 두 개의 입력층으로부터 분기되어 진행된 후 마지막에는 하나의 출력을 예측하는 모델이 됨.\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "inputs = Input(shape=(50,1))\n",
    "lstm_layer = LSTM(10)(inputs) # RNN의 일종인 LSTM을 사용\n",
    "x = Dense(10, activation='relu')(lstm_layer)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=inputs, outputs=output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
