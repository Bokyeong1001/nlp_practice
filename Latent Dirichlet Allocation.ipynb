{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complete-spanish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ignored-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame({'document':documents})\n",
    "# 특수 문자 제거\n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "# 길이가 3이하인 단어는 제거 (길이가 짧은 단어 제거)\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "# 전체 단어에 대한 소문자 변환\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "resistant-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english') # NLTK로부터 불용어를 받아옵니다.\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split()) # 토큰화\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "# 불용어를 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greenhouse-dominican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [well, sure, story, seem, biased, disagree, st...\n",
       "1    [yeah, expect, people, read, actually, accept,...\n",
       "2    [although, realize, principle, strongest, poin...\n",
       "3    [notwithstanding, legitimate, fuss, proposal, ...\n",
       "4    [well, change, scoring, playoff, pool, unfortu...\n",
       "Name: clean_doc, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "instructional-superintendent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(52, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 2), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 2), (86, 1), (87, 1), (88, 1), (89, 1)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(tokenized_doc)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]\n",
    "print(corpus[1]) # 수행된 결과에서 두번째 뉴스 출력. 첫번째 문서의 인덱스는 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "multiple-personal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faith\n"
     ]
    }
   ],
   "source": [
    "print(dictionary[66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "objective-think",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.015*\"weaver\" + 0.013*\"allocation\" + 0.012*\"bandwidth\" + 0.012*\"expose\"')\n",
      "(1, '0.019*\"game\" + 0.017*\"team\" + 0.012*\"games\" + 0.012*\"year\"')\n",
      "(2, '0.011*\"people\" + 0.010*\"would\" + 0.006*\"government\" + 0.005*\"right\"')\n",
      "(3, '0.014*\"runs\" + 0.011*\"ball\" + 0.010*\"year\" + 0.008*\"pitching\"')\n",
      "(4, '0.045*\"stream\" + 0.009*\"captain\" + 0.008*\"laptop\" + 0.008*\"astros\"')\n",
      "(5, '0.027*\"period\" + 0.013*\"power\" + 0.011*\"scorer\" + 0.007*\"play\"')\n",
      "(6, '0.021*\"file\" + 0.012*\"program\" + 0.009*\"window\" + 0.009*\"output\"')\n",
      "(7, '0.013*\"would\" + 0.011*\"people\" + 0.009*\"think\" + 0.007*\"know\"')\n",
      "(8, '0.018*\"pitt\" + 0.018*\"gordon\" + 0.016*\"banks\" + 0.015*\"soon\"')\n",
      "(9, '0.012*\"colorado\" + 0.008*\"seagate\" + 0.007*\"shock\" + 0.007*\"japanese\"')\n",
      "(10, '0.010*\"book\" + 0.010*\"article\" + 0.007*\"books\" + 0.007*\"posting\"')\n",
      "(11, '0.013*\"like\" + 0.009*\"time\" + 0.008*\"good\" + 0.008*\"would\"')\n",
      "(12, '0.025*\"food\" + 0.012*\"smokeless\" + 0.012*\"nist\" + 0.010*\"ncsl\"')\n",
      "(13, '0.016*\"space\" + 0.007*\"information\" + 0.006*\"data\" + 0.006*\"research\"')\n",
      "(14, '0.008*\"water\" + 0.006*\"insurance\" + 0.005*\"list\" + 0.005*\"service\"')\n",
      "(15, '0.013*\"thanks\" + 0.011*\"windows\" + 0.011*\"would\" + 0.010*\"please\"')\n",
      "(16, '0.020*\"president\" + 0.014*\"going\" + 0.011*\"think\" + 0.010*\"said\"')\n",
      "(17, '0.010*\"helmet\" + 0.009*\"docs\" + 0.008*\"ethernet\" + 0.007*\"conductor\"')\n",
      "(18, '0.014*\"encryption\" + 0.012*\"chip\" + 0.011*\"keys\" + 0.011*\"security\"')\n",
      "(19, '0.021*\"armenian\" + 0.018*\"armenians\" + 0.015*\"turkish\" + 0.015*\"jews\"')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 20 #20개의 토픽, k=20\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intense-local",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode characters in position 18-20: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-063ee2783176>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\gensim.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \"\"\"\n\u001b[0;32m    123\u001b[0m     \u001b[0mopts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_topic_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mvis_prepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\_prepare.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics, start_index)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[0mterm_frequency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm_topic_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     topic_info = _topic_info(topic_term_dists, topic_proportion,\n\u001b[0m\u001b[0;32m    441\u001b[0m                              \u001b[0mterm_frequency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterm_topic_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                              n_jobs, start_index)\n",
      "\u001b[1;32mc:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\_prepare.py\u001b[0m in \u001b[0;36m_topic_info\u001b[1;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs, start_index)\u001b[0m\n\u001b[0;32m    275\u001b[0m         ])\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m     top_terms = pd.concat(Parallel(n_jobs=n_jobs)\n\u001b[0m\u001b[0;32m    278\u001b[0m                           (delayed(_find_relevance_chunks)(log_ttd, log_lift, R, ls)\n\u001b[0;32m    279\u001b[0m                           for ls in _job_chunks(lambda_seq, n_jobs)))\n",
      "\u001b[1;32mc:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m             \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m             \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_effective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_initialize_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;34m\"\"\"Build a process or thread pool and return the number of workers\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n\u001b[0m\u001b[0;32m    741\u001b[0m                                              **self._backend_args)\n\u001b[0;32m    742\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupports_timeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mconfigure\u001b[1;34m(self, n_jobs, parallel, prefer, require, idle_worker_timeout, **memmappingexecutor_args)\u001b[0m\n\u001b[0;32m    492\u001b[0m                 SequentialBackend(nesting_level=self.nesting_level))\n\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m         self._workers = get_memmapping_executor(\n\u001b[0m\u001b[0;32m    495\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midle_worker_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[0menv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_worker_env\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\executor.py\u001b[0m in \u001b[0;36mget_memmapping_executor\u001b[1;34m(n_jobs, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_memmapping_executor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mMemmappingExecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_memmapping_executor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\executor.py\u001b[0m in \u001b[0;36mget_memmapping_executor\u001b[1;34m(cls, n_jobs, timeout, initializer, initargs, env, temp_folder, context_id, **backend_args)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0m_executor_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mmanager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTemporaryResourcesManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# reducers access the temporary folder in which to store temporary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\_memmapping_reducer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, temp_folder_root, context_id)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[1;31m# exposes exposes too many low-level details.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mcontext_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muuid4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_current_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_current_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\_memmapping_reducer.py\u001b[0m in \u001b[0;36mset_current_context\u001b[1;34m(self, context_id)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_current_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_context_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_new_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_new_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\_memmapping_reducer.py\u001b[0m in \u001b[0;36mregister_new_context\u001b[1;34m(self, context_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m                 \u001b[0mnew_folder_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_temp_folder_root\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             )\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_folder_finalizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_folder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_temp_folders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_folder_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\_memmapping_reducer.py\u001b[0m in \u001b[0;36mregister_folder_finalizer\u001b[1;34m(self, pool_subfolder, context_id)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# semaphores and pipes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[0mpool_module_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwhichmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelete_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'delete_folder'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mresource_tracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_subfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"folder\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py\u001b[0m in \u001b[0;36mregister\u001b[1;34m(self, name, rtype)\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;34m'''Register a named resource, and increment its refcount.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'REGISTER'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0munregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py\u001b[0m in \u001b[0;36m_send\u001b[1;34m(self, cmd, name, rtype)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_send\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{0}:{1}:{2}\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[1;31m# posix guarantees that writes to a pipe of less than PIPE_BUF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode characters in position 18-20: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "joint-findings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 문서의 topic 비율은 [(2, 0.7126882), (7, 0.18043402), (19, 0.0931525)]\n",
      "1 번째 문서의 topic 비율은 [(3, 0.027568934), (7, 0.83078647), (14, 0.027561428), (18, 0.09300533)]\n",
      "2 번째 문서의 topic 비율은 [(2, 0.71795857), (7, 0.26750332)]\n",
      "3 번째 문서의 topic 비율은 [(7, 0.21305376), (8, 0.041185897), (9, 0.016395262), (10, 0.020110868), (11, 0.3044418), (18, 0.39384028)]\n",
      "4 번째 문서의 topic 비율은 [(1, 0.3180421), (5, 0.28076062), (6, 0.04126207), (7, 0.33029193)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "for i, topic_list in enumerate(ldamodel[corpus]):\n",
    "    if i==5:\n",
    "        break\n",
    "    print(i,'번째 문서의 topic 비율은',topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "subject-carrier",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def make_topictable_per_doc(ldamodel, corpus):\n",
    "    topic_table = pd.DataFrame()\n",
    "\n",
    "    # 몇 번째 문서인지를 의미하는 문서 번호와 해당 문서의 토픽 비중을 한 줄씩 꺼내온다.\n",
    "    for i, topic_list in enumerate(ldamodel[corpus]):\n",
    "        doc = topic_list[0] if ldamodel.per_word_topics else topic_list            \n",
    "        doc = sorted(doc, key=lambda x: (x[1]), reverse=True)\n",
    "        # 각 문서에 대해서 비중이 높은 토픽순으로 토픽을 정렬한다.\n",
    "        # EX) 정렬 전 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (10번 토픽, 5%), (12번 토픽, 21.5%), \n",
    "        # Ex) 정렬 후 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (12번 토픽, 21.5%), (10번 토픽, 5%)\n",
    "        # 48 > 25 > 21 > 5 순으로 정렬이 된 것.\n",
    "\n",
    "        # 모든 문서에 대해서 각각 아래를 수행\n",
    "        for j, (topic_num, prop_topic) in enumerate(doc): #  몇 번 토픽인지와 비중을 나눠서 저장한다.\n",
    "            if j == 0:  # 정렬을 한 상태이므로 가장 앞에 있는 것이 가장 비중이 높은 토픽\n",
    "                topic_table = topic_table.append(pd.Series([int(topic_num), round(prop_topic,4), topic_list]), ignore_index=True)\n",
    "                # 가장 비중이 높은 토픽과, 가장 비중이 높은 토픽의 비중과, 전체 토픽의 비중을 저장한다.\n",
    "            else:\n",
    "                break\n",
    "    return(topic_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "future-creator",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\윤보경\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문서 번호</th>\n",
       "      <th>가장 비중이 높은 토픽</th>\n",
       "      <th>가장 높은 토픽의 비중</th>\n",
       "      <th>각 토픽의 비중</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7126</td>\n",
       "      <td>[(2, 0.7126213), (7, 0.18049982), (19, 0.09315...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.8308</td>\n",
       "      <td>[(3, 0.02756895), (7, 0.8307869), (14, 0.02756...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>[(2, 0.71791804), (7, 0.2675438)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>[(7, 0.21306685), (8, 0.041185893), (9, 0.0163...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>[(1, 0.3181106), (5, 0.28074548), (6, 0.041472...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5546</td>\n",
       "      <td>[(7, 0.5546116), (10, 0.4062368)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.2661</td>\n",
       "      <td>[(3, 0.13018247), (4, 0.014756404), (6, 0.1774...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5330</td>\n",
       "      <td>[(2, 0.43391842), (7, 0.5330334), (14, 0.01908...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>[(7, 0.6741697), (15, 0.13241398), (16, 0.1683...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.6883</td>\n",
       "      <td>[(2, 0.09146587), (9, 0.028890252), (11, 0.688...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   문서 번호  가장 비중이 높은 토픽  가장 높은 토픽의 비중  \\\n",
       "0      0           2.0        0.7126   \n",
       "1      1           7.0        0.8308   \n",
       "2      2           2.0        0.7179   \n",
       "3      3          18.0        0.3938   \n",
       "4      4           7.0        0.3300   \n",
       "5      5           7.0        0.5546   \n",
       "6      6          11.0        0.2661   \n",
       "7      7           7.0        0.5330   \n",
       "8      8           7.0        0.6742   \n",
       "9      9          11.0        0.6883   \n",
       "\n",
       "                                            각 토픽의 비중  \n",
       "0  [(2, 0.7126213), (7, 0.18049982), (19, 0.09315...  \n",
       "1  [(3, 0.02756895), (7, 0.8307869), (14, 0.02756...  \n",
       "2                  [(2, 0.71791804), (7, 0.2675438)]  \n",
       "3  [(7, 0.21306685), (8, 0.041185893), (9, 0.0163...  \n",
       "4  [(1, 0.3181106), (5, 0.28074548), (6, 0.041472...  \n",
       "5                  [(7, 0.5546116), (10, 0.4062368)]  \n",
       "6  [(3, 0.13018247), (4, 0.014756404), (6, 0.1774...  \n",
       "7  [(2, 0.43391842), (7, 0.5330334), (14, 0.01908...  \n",
       "8  [(7, 0.6741697), (15, 0.13241398), (16, 0.1683...  \n",
       "9  [(2, 0.09146587), (9, 0.028890252), (11, 0.688...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topictable = make_topictable_per_doc(ldamodel, corpus)\n",
    "topictable = topictable.reset_index() # 문서 번호을 의미하는 열(column)로 사용하기 위해서 인덱스 열을 하나 더 만든다.\n",
    "topictable.columns = ['문서 번호', '가장 비중이 높은 토픽', '가장 높은 토픽의 비중', '각 토픽의 비중']\n",
    "topictable[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-cylinder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
